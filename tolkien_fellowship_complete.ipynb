{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.utils as ku\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "data = open('texts/fellowship-complete.txt').read()\n",
    "\n",
    "data = data.replace(',', 'pausesentence')\n",
    "data = data.replace('!', 'exclamationmark')\n",
    "data = data.replace('?', '.')\n",
    "\n",
    "corpus = data.lower().split(\". \")\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    corpus [i] =  corpus [i] + 'endofthesentence'\n",
    "    \n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# create input sequences using list of tokens\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "label = ku.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 758, 64)           940736    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 758, 40)           13600     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 758, 40)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 40)                9760      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14699)             602659    \n",
      "=================================================================\n",
      "Total params: 1,568,395\n",
      "Trainable params: 1,568,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(20, return_sequences=True)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Bidirectional(LSTM(20)))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.train.AdamOptimizer(), metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_number = 1723\n",
    "\n",
    "training_data = []\n",
    "for i in range(99):\n",
    "    training_data.append([predictors[i*split_number:(i+1)*split_number], label[i*split_number:(i+1)*split_number]])\n",
    "training_data.append([predictors[(i+1)*split_number:], label[(i+1)*split_number:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1723/1723 [==============================] - 104s 61ms/step - loss: 8.5978 - acc: 0.0244\n",
      "Epoch 2/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 6.0541 - acc: 0.0441\n",
      "Epoch 3/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 5.8077 - acc: 0.0441\n",
      "Epoch 4/100\n",
      "1723/1723 [==============================] - 101s 58ms/step - loss: 5.7513 - acc: 0.0441\n",
      "Epoch 5/100\n",
      "1723/1723 [==============================] - 101s 58ms/step - loss: 5.7281 - acc: 0.0435\n",
      "Epoch 6/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 5.7175 - acc: 0.0441\n",
      "Epoch 7/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 5.7024 - acc: 0.0441\n",
      "Epoch 8/100\n",
      "1723/1723 [==============================] - 99s 57ms/step - loss: 5.6986 - acc: 0.0441\n",
      "Epoch 9/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 5.6708 - acc: 0.0441\n",
      "Epoch 10/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 5.6310 - acc: 0.0441\n",
      "Epoch 11/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 5.5794 - acc: 0.0389\n",
      "Epoch 12/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 5.5367 - acc: 0.0429\n",
      "Epoch 13/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 5.4803 - acc: 0.0441\n",
      "Epoch 14/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 5.4119 - acc: 0.0459\n",
      "Epoch 15/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 5.3637 - acc: 0.0383\n",
      "Epoch 16/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 5.3120 - acc: 0.0435\n",
      "Epoch 17/100\n",
      "1723/1723 [==============================] - 101s 58ms/step - loss: 5.2958 - acc: 0.0459\n",
      "Epoch 18/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 5.2642 - acc: 0.0447\n",
      "Epoch 19/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 5.2147 - acc: 0.0482\n",
      "Epoch 20/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 5.1722 - acc: 0.0493\n",
      "Epoch 21/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 5.1488 - acc: 0.0488\n",
      "Epoch 22/100\n",
      "1723/1723 [==============================] - 101s 58ms/step - loss: 5.1206 - acc: 0.0488\n",
      "Epoch 23/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 5.0950 - acc: 0.0488\n",
      "Epoch 24/100\n",
      "1723/1723 [==============================] - 99s 58ms/step - loss: 5.0715 - acc: 0.0511\n",
      "Epoch 25/100\n",
      "1723/1723 [==============================] - 99s 58ms/step - loss: 5.0747 - acc: 0.0517\n",
      "Epoch 26/100\n",
      "1723/1723 [==============================] - 99s 57ms/step - loss: 5.0530 - acc: 0.0528\n",
      "Epoch 27/100\n",
      "1723/1723 [==============================] - 99s 57ms/step - loss: 4.9855 - acc: 0.0563\n",
      "Epoch 28/100\n",
      "1723/1723 [==============================] - 116s 67ms/step - loss: 5.0266 - acc: 0.0447\n",
      "Epoch 29/100\n",
      "1723/1723 [==============================] - 124s 72ms/step - loss: 4.9888 - acc: 0.0476\n",
      "Epoch 30/100\n",
      "1723/1723 [==============================] - 122s 71ms/step - loss: 4.9492 - acc: 0.0569\n",
      "Epoch 31/100\n",
      "1723/1723 [==============================] - 121s 70ms/step - loss: 4.9111 - acc: 0.0598\n",
      "Epoch 32/100\n",
      "1723/1723 [==============================] - 120s 70ms/step - loss: 4.8766 - acc: 0.0569\n",
      "Epoch 33/100\n",
      "1723/1723 [==============================] - 119s 69ms/step - loss: 4.8464 - acc: 0.0551\n",
      "Epoch 34/100\n",
      "1723/1723 [==============================] - 118s 69ms/step - loss: 4.8035 - acc: 0.0569\n",
      "Epoch 35/100\n",
      "1723/1723 [==============================] - 116s 67ms/step - loss: 4.7832 - acc: 0.0586\n",
      "Epoch 36/100\n",
      "1723/1723 [==============================] - 117s 68ms/step - loss: 4.7661 - acc: 0.0528\n",
      "Epoch 37/100\n",
      "1723/1723 [==============================] - 116s 67ms/step - loss: 4.7393 - acc: 0.0592\n",
      "Epoch 38/100\n",
      "1723/1723 [==============================] - 116s 68ms/step - loss: 4.7812 - acc: 0.0540\n",
      "Epoch 39/100\n",
      "1723/1723 [==============================] - 114s 66ms/step - loss: 4.7178 - acc: 0.0644\n",
      "Epoch 40/100\n",
      "1723/1723 [==============================] - 113s 66ms/step - loss: 4.6864 - acc: 0.0633\n",
      "Epoch 41/100\n",
      "1723/1723 [==============================] - 113s 66ms/step - loss: 4.6635 - acc: 0.0662\n",
      "Epoch 42/100\n",
      "1723/1723 [==============================] - 113s 65ms/step - loss: 4.6540 - acc: 0.0662\n",
      "Epoch 43/100\n",
      "1723/1723 [==============================] - 113s 65ms/step - loss: 4.6659 - acc: 0.0586\n",
      "Epoch 44/100\n",
      "1723/1723 [==============================] - 112s 65ms/step - loss: 4.6015 - acc: 0.0691\n",
      "Epoch 45/100\n",
      "1723/1723 [==============================] - 111s 65ms/step - loss: 4.5859 - acc: 0.0667\n",
      "Epoch 46/100\n",
      "1723/1723 [==============================] - 112s 65ms/step - loss: 4.5407 - acc: 0.0696\n",
      "Epoch 47/100\n",
      "1723/1723 [==============================] - 111s 64ms/step - loss: 4.5225 - acc: 0.0662\n",
      "Epoch 48/100\n",
      "1723/1723 [==============================] - 110s 64ms/step - loss: 4.5223 - acc: 0.0644\n",
      "Epoch 49/100\n",
      "1723/1723 [==============================] - 111s 64ms/step - loss: 4.5039 - acc: 0.0696\n",
      "Epoch 50/100\n",
      "1723/1723 [==============================] - 110s 64ms/step - loss: 4.4857 - acc: 0.0737\n",
      "Epoch 51/100\n",
      "1723/1723 [==============================] - 109s 64ms/step - loss: 4.4502 - acc: 0.0667\n",
      "Epoch 52/100\n",
      "1723/1723 [==============================] - 109s 63ms/step - loss: 4.4197 - acc: 0.0720\n",
      "Epoch 53/100\n",
      "1723/1723 [==============================] - 110s 64ms/step - loss: 4.4095 - acc: 0.0766\n",
      "Epoch 54/100\n",
      "1723/1723 [==============================] - 110s 64ms/step - loss: 4.3758 - acc: 0.0760\n",
      "Epoch 55/100\n",
      "1723/1723 [==============================] - 109s 63ms/step - loss: 4.3970 - acc: 0.0754\n",
      "Epoch 56/100\n",
      "1723/1723 [==============================] - 110s 64ms/step - loss: 4.4017 - acc: 0.0813\n",
      "Epoch 57/100\n",
      "1723/1723 [==============================] - 110s 64ms/step - loss: 4.4744 - acc: 0.0720\n",
      "Epoch 58/100\n",
      "1723/1723 [==============================] - 110s 64ms/step - loss: 4.3751 - acc: 0.0749\n",
      "Epoch 59/100\n",
      "1723/1723 [==============================] - 109s 63ms/step - loss: 4.3225 - acc: 0.0853\n",
      "Epoch 60/100\n",
      "1723/1723 [==============================] - 109s 63ms/step - loss: 4.3119 - acc: 0.0853\n",
      "Epoch 61/100\n",
      "1723/1723 [==============================] - 109s 63ms/step - loss: 4.3396 - acc: 0.0818\n",
      "Epoch 62/100\n",
      "1723/1723 [==============================] - 109s 63ms/step - loss: 4.2769 - acc: 0.0871\n",
      "Epoch 63/100\n",
      "1723/1723 [==============================] - 109s 63ms/step - loss: 4.2526 - acc: 0.0894\n",
      "Epoch 64/100\n",
      "1723/1723 [==============================] - 108s 62ms/step - loss: 4.2647 - acc: 0.0894\n",
      "Epoch 65/100\n",
      "1723/1723 [==============================] - 108s 63ms/step - loss: 4.2498 - acc: 0.0871\n",
      "Epoch 66/100\n",
      "1723/1723 [==============================] - 108s 63ms/step - loss: 4.1974 - acc: 0.0894\n",
      "Epoch 67/100\n",
      "1723/1723 [==============================] - 108s 63ms/step - loss: 4.1906 - acc: 0.0934\n",
      "Epoch 68/100\n",
      "1723/1723 [==============================] - 108s 63ms/step - loss: 4.1778 - acc: 0.0900\n",
      "Epoch 69/100\n",
      "1723/1723 [==============================] - 108s 62ms/step - loss: 4.2396 - acc: 0.0900\n",
      "Epoch 70/100\n",
      "1723/1723 [==============================] - 109s 63ms/step - loss: 4.1752 - acc: 0.1010\n",
      "Epoch 71/100\n",
      "1723/1723 [==============================] - 109s 63ms/step - loss: 4.1890 - acc: 0.0963\n",
      "Epoch 72/100\n",
      "1723/1723 [==============================] - 109s 63ms/step - loss: 4.1570 - acc: 0.0946\n",
      "Epoch 73/100\n",
      "1723/1723 [==============================] - 108s 63ms/step - loss: 4.1261 - acc: 0.0929\n",
      "Epoch 74/100\n",
      "1723/1723 [==============================] - 109s 63ms/step - loss: 4.1229 - acc: 0.0975\n",
      "Epoch 75/100\n",
      "1723/1723 [==============================] - 109s 63ms/step - loss: 4.2320 - acc: 0.0963\n",
      "Epoch 76/100\n",
      "1723/1723 [==============================] - 108s 63ms/step - loss: 4.1305 - acc: 0.0929\n",
      "Epoch 77/100\n",
      "1723/1723 [==============================] - 108s 63ms/step - loss: 4.0789 - acc: 0.1010\n",
      "Epoch 78/100\n",
      "1723/1723 [==============================] - 108s 63ms/step - loss: 4.1736 - acc: 0.1033\n",
      "Epoch 79/100\n",
      "1723/1723 [==============================] - 102s 59ms/step - loss: 4.1274 - acc: 0.1016\n",
      "Epoch 80/100\n",
      "1723/1723 [==============================] - 97s 57ms/step - loss: 4.0578 - acc: 0.1097\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1723/1723 [==============================] - 104s 60ms/step - loss: 4.0050 - acc: 0.1091\n",
      "Epoch 82/100\n",
      "1723/1723 [==============================] - 100s 58ms/step - loss: 3.9957 - acc: 0.1097\n",
      "Epoch 83/100\n",
      "1723/1723 [==============================] - 101s 59ms/step - loss: 3.9510 - acc: 0.1091\n",
      "Epoch 84/100\n",
      "1723/1723 [==============================] - 105s 61ms/step - loss: 3.9475 - acc: 0.1161\n",
      "Epoch 85/100\n",
      "1723/1723 [==============================] - 103s 60ms/step - loss: 3.9131 - acc: 0.1178\n",
      "Epoch 86/100\n",
      "1723/1723 [==============================] - 105s 61ms/step - loss: 3.8922 - acc: 0.1184\n",
      "Epoch 87/100\n",
      "1723/1723 [==============================] - 98s 57ms/step - loss: 3.8649 - acc: 0.1201\n",
      "Epoch 88/100\n",
      "1723/1723 [==============================] - 93s 54ms/step - loss: 3.8434 - acc: 0.1178\n",
      "Epoch 89/100\n",
      "1723/1723 [==============================] - 90s 52ms/step - loss: 3.8340 - acc: 0.1283\n",
      "Epoch 90/100\n",
      "1723/1723 [==============================] - 94s 55ms/step - loss: 3.7840 - acc: 0.1346\n",
      "Epoch 91/100\n",
      "1723/1723 [==============================] - 95s 55ms/step - loss: 3.7819 - acc: 0.1312\n",
      "Epoch 92/100\n",
      "1723/1723 [==============================] - 99s 57ms/step - loss: 3.8141 - acc: 0.1265\n",
      "Epoch 93/100\n",
      "1723/1723 [==============================] - 99s 58ms/step - loss: 3.7805 - acc: 0.1294\n",
      "Epoch 94/100\n",
      "1723/1723 [==============================] - 94s 54ms/step - loss: 3.8742 - acc: 0.1207\n",
      "Epoch 95/100\n",
      "1723/1723 [==============================] - 92s 53ms/step - loss: 4.0110 - acc: 0.1196\n",
      "Epoch 96/100\n",
      "1723/1723 [==============================] - 93s 54ms/step - loss: 3.7875 - acc: 0.1300\n",
      "Epoch 97/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 3.7309 - acc: 0.1381\n",
      "Epoch 98/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 3.6908 - acc: 0.1416\n",
      "Epoch 99/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 3.6563 - acc: 0.1335\n",
      "Epoch 100/100\n",
      "1723/1723 [==============================] - 90s 52ms/step - loss: 3.6357 - acc: 0.1364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12a1b8ef0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data[10][0], training_data[10][1], epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"models/model_complete.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 9.6597 - acc: 0.0383\n",
      "Epoch 2/100\n",
      "1723/1723 [==============================] - 89s 52ms/step - loss: 7.8399 - acc: 0.0598\n",
      "Epoch 3/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 6.3570 - acc: 0.0575\n",
      "Epoch 4/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 5.8140 - acc: 0.0609\n",
      "Epoch 5/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 5.6148 - acc: 0.0656\n",
      "Epoch 6/100\n",
      "1723/1723 [==============================] - 89s 52ms/step - loss: 5.5097 - acc: 0.0650\n",
      "Epoch 7/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 5.4147 - acc: 0.0609\n",
      "Epoch 8/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 5.3583 - acc: 0.0679\n",
      "Epoch 9/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 5.2811 - acc: 0.0714\n",
      "Epoch 10/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 5.2212 - acc: 0.0754\n",
      "Epoch 11/100\n",
      "1723/1723 [==============================] - 89s 52ms/step - loss: 5.1472 - acc: 0.0766\n",
      "Epoch 12/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 5.0820 - acc: 0.0871\n",
      "Epoch 13/100\n",
      "1723/1723 [==============================] - 90s 52ms/step - loss: 4.9954 - acc: 0.0807\n",
      "Epoch 14/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 4.9389 - acc: 0.0917\n",
      "Epoch 15/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 4.8984 - acc: 0.0871\n",
      "Epoch 16/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 4.8600 - acc: 0.0836\n",
      "Epoch 17/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 4.7836 - acc: 0.0894\n",
      "Epoch 18/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 4.7341 - acc: 0.0969\n",
      "Epoch 19/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 4.7220 - acc: 0.0929\n",
      "Epoch 20/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 4.6722 - acc: 0.0940\n",
      "Epoch 21/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 4.5888 - acc: 0.0981\n",
      "Epoch 22/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 4.5597 - acc: 0.0975\n",
      "Epoch 23/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 4.6297 - acc: 0.0917\n",
      "Epoch 24/100\n",
      "1723/1723 [==============================] - 91s 53ms/step - loss: 4.5748 - acc: 0.1050\n",
      "Epoch 25/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 4.5162 - acc: 0.0987\n",
      "Epoch 26/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 4.6904 - acc: 0.0992\n",
      "Epoch 27/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 4.6070 - acc: 0.1050\n",
      "Epoch 28/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 4.4277 - acc: 0.1056\n",
      "Epoch 29/100\n",
      "1723/1723 [==============================] - 85s 50ms/step - loss: 4.3817 - acc: 0.1080\n",
      "Epoch 30/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 4.3220 - acc: 0.1056\n",
      "Epoch 31/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 4.2687 - acc: 0.1126\n",
      "Epoch 32/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 4.2461 - acc: 0.1132\n",
      "Epoch 33/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 4.2016 - acc: 0.1097\n",
      "Epoch 34/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 4.1784 - acc: 0.1184\n",
      "Epoch 35/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 4.1242 - acc: 0.1190\n",
      "Epoch 36/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 4.1008 - acc: 0.1213\n",
      "Epoch 37/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 4.0469 - acc: 0.1236\n",
      "Epoch 38/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 4.0114 - acc: 0.1190\n",
      "Epoch 39/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 3.9986 - acc: 0.1294\n",
      "Epoch 40/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 4.0403 - acc: 0.1178\n",
      "Epoch 41/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 3.9797 - acc: 0.1288\n",
      "Epoch 42/100\n",
      "1723/1723 [==============================] - 99s 57ms/step - loss: 3.9970 - acc: 0.1306\n",
      "Epoch 43/100\n",
      "1723/1723 [==============================] - 141s 82ms/step - loss: 3.8949 - acc: 0.1381\n",
      "Epoch 44/100\n",
      "1723/1723 [==============================] - 143s 83ms/step - loss: 3.8384 - acc: 0.1352\n",
      "Epoch 45/100\n",
      "1723/1723 [==============================] - 142s 82ms/step - loss: 3.8122 - acc: 0.1387\n",
      "Epoch 46/100\n",
      "1723/1723 [==============================] - 140s 82ms/step - loss: 3.7607 - acc: 0.1468\n",
      "Epoch 47/100\n",
      "1723/1723 [==============================] - 236s 137ms/step - loss: 3.7581 - acc: 0.1480\n",
      "Epoch 48/100\n",
      "1723/1723 [==============================] - 90s 52ms/step - loss: 3.7313 - acc: 0.1550\n",
      "Epoch 49/100\n",
      "1723/1723 [==============================] - 89s 52ms/step - loss: 3.6928 - acc: 0.1497\n",
      "Epoch 50/100\n",
      "1723/1723 [==============================] - 105s 61ms/step - loss: 3.6464 - acc: 0.1486\n",
      "Epoch 51/100\n",
      "1723/1723 [==============================] - 99s 58ms/step - loss: 3.6404 - acc: 0.1625\n",
      "Epoch 52/100\n",
      "1723/1723 [==============================] - 89s 51ms/step - loss: 3.6138 - acc: 0.1463\n",
      "Epoch 53/100\n",
      "1723/1723 [==============================] - 89s 52ms/step - loss: 3.6176 - acc: 0.1619\n",
      "Epoch 54/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 3.5957 - acc: 0.1521\n",
      "Epoch 55/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 3.5520 - acc: 0.1608\n",
      "Epoch 56/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 3.5377 - acc: 0.1637\n",
      "Epoch 57/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 3.5655 - acc: 0.1625\n",
      "Epoch 58/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 3.4988 - acc: 0.1608\n",
      "Epoch 59/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 3.4702 - acc: 0.1701\n",
      "Epoch 60/100\n",
      "1723/1723 [==============================] - 89s 52ms/step - loss: 3.4077 - acc: 0.1695\n",
      "Epoch 61/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 3.4223 - acc: 0.1747\n",
      "Epoch 62/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 3.4209 - acc: 0.1706\n",
      "Epoch 63/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 3.3778 - acc: 0.1689\n",
      "Epoch 64/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 3.3682 - acc: 0.1764\n",
      "Epoch 65/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 3.3154 - acc: 0.1851\n",
      "Epoch 66/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 3.2727 - acc: 0.1915\n",
      "Epoch 67/100\n",
      "1723/1723 [==============================] - 89s 51ms/step - loss: 3.2337 - acc: 0.2020\n",
      "Epoch 68/100\n",
      "1723/1723 [==============================] - 90s 52ms/step - loss: 3.2095 - acc: 0.2014\n",
      "Epoch 69/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 3.2419 - acc: 0.2020\n",
      "Epoch 70/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 3.2110 - acc: 0.2014\n",
      "Epoch 71/100\n",
      "1723/1723 [==============================] - 116s 67ms/step - loss: 3.1844 - acc: 0.1962\n",
      "Epoch 72/100\n",
      "1723/1723 [==============================] - 99s 57ms/step - loss: 3.1866 - acc: 0.2026\n",
      "Epoch 73/100\n",
      "1723/1723 [==============================] - 93s 54ms/step - loss: 3.1995 - acc: 0.2095\n",
      "Epoch 74/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 3.6269 - acc: 0.1741\n",
      "Epoch 75/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 3.3093 - acc: 0.1915\n",
      "Epoch 76/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 3.1201 - acc: 0.2165\n",
      "Epoch 77/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 3.0669 - acc: 0.2130\n",
      "Epoch 78/100\n",
      "1723/1723 [==============================] - 89s 52ms/step - loss: 3.0654 - acc: 0.2200\n",
      "Epoch 79/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 2.9979 - acc: 0.2165\n",
      "Epoch 80/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 3.0156 - acc: 0.2223\n",
      "Epoch 81/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 2.9943 - acc: 0.2298\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1723/1723 [==============================] - 88s 51ms/step - loss: 2.9385 - acc: 0.2339\n",
      "Epoch 83/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 2.9055 - acc: 0.2356\n",
      "Epoch 84/100\n",
      "1723/1723 [==============================] - 90s 52ms/step - loss: 2.8870 - acc: 0.2606\n",
      "Epoch 85/100\n",
      "1723/1723 [==============================] - 89s 51ms/step - loss: 2.8606 - acc: 0.2525\n",
      "Epoch 86/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 2.8510 - acc: 0.2542\n",
      "Epoch 87/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 2.8249 - acc: 0.2559\n",
      "Epoch 88/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 2.7919 - acc: 0.2647\n",
      "Epoch 89/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 2.7838 - acc: 0.2583\n",
      "Epoch 90/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 2.7376 - acc: 0.2641\n",
      "Epoch 91/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 2.7965 - acc: 0.2623\n",
      "Epoch 92/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 2.7612 - acc: 0.2525\n",
      "Epoch 93/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 2.7557 - acc: 0.2716\n",
      "Epoch 94/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 2.9885 - acc: 0.2443\n",
      "Epoch 95/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 3.0274 - acc: 0.2443\n",
      "Epoch 96/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 2.8388 - acc: 0.2548\n",
      "Epoch 97/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 2.8149 - acc: 0.2647\n",
      "Epoch 98/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 2.7552 - acc: 0.2745\n",
      "Epoch 99/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 2.7332 - acc: 0.2664\n",
      "Epoch 100/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 2.6448 - acc: 0.2902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12a1d4a58>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data[60][0], training_data[60][1], epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"models/model_complete.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 10.5150 - acc: 0.0493\n",
      "Epoch 2/100\n",
      "1723/1723 [==============================] - 83s 48ms/step - loss: 9.6498 - acc: 0.0662\n",
      "Epoch 3/100\n",
      "1723/1723 [==============================] - 83s 48ms/step - loss: 9.1191 - acc: 0.0760\n",
      "Epoch 4/100\n",
      "1723/1723 [==============================] - 83s 48ms/step - loss: 8.5739 - acc: 0.0778\n",
      "Epoch 5/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 7.2737 - acc: 0.0696\n",
      "Epoch 6/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 6.4768 - acc: 0.0633\n",
      "Epoch 7/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 5.9461 - acc: 0.0656\n",
      "Epoch 8/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 5.7391 - acc: 0.0667\n",
      "Epoch 9/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 5.6435 - acc: 0.0702\n",
      "Epoch 10/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 5.5576 - acc: 0.0679\n",
      "Epoch 11/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 5.4997 - acc: 0.0691\n",
      "Epoch 12/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 5.4734 - acc: 0.0685\n",
      "Epoch 13/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 5.3968 - acc: 0.0696\n",
      "Epoch 14/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 5.3402 - acc: 0.0743\n",
      "Epoch 15/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 5.2795 - acc: 0.0731\n",
      "Epoch 16/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 5.2245 - acc: 0.0772\n",
      "Epoch 17/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 5.1713 - acc: 0.0824\n",
      "Epoch 18/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 5.1317 - acc: 0.0853\n",
      "Epoch 19/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 5.0868 - acc: 0.0888\n",
      "Epoch 20/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 5.0128 - acc: 0.0894\n",
      "Epoch 21/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 4.9799 - acc: 0.0871\n",
      "Epoch 22/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 4.9462 - acc: 0.0900\n",
      "Epoch 23/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 4.8958 - acc: 0.0981\n",
      "Epoch 24/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 4.8162 - acc: 0.1045\n",
      "Epoch 25/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 4.7434 - acc: 0.1045\n",
      "Epoch 26/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 4.6962 - acc: 0.1039\n",
      "Epoch 27/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 4.6647 - acc: 0.1016\n",
      "Epoch 28/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 4.6008 - acc: 0.1085\n",
      "Epoch 29/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 4.5433 - acc: 0.1103\n",
      "Epoch 30/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 4.4834 - acc: 0.1103\n",
      "Epoch 31/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 4.4775 - acc: 0.1178\n",
      "Epoch 32/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 4.4142 - acc: 0.1207\n",
      "Epoch 33/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 4.3657 - acc: 0.1161\n",
      "Epoch 34/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 4.3227 - acc: 0.1306\n",
      "Epoch 35/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 4.2651 - acc: 0.1248\n",
      "Epoch 36/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 4.2509 - acc: 0.1288\n",
      "Epoch 37/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 4.1708 - acc: 0.1312\n",
      "Epoch 38/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 4.1115 - acc: 0.1341\n",
      "Epoch 39/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 4.0526 - acc: 0.1352\n",
      "Epoch 40/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 4.0362 - acc: 0.1457\n",
      "Epoch 41/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 3.9792 - acc: 0.1393\n",
      "Epoch 42/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 3.9430 - acc: 0.1509\n",
      "Epoch 43/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 3.8916 - acc: 0.1463\n",
      "Epoch 44/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 3.8579 - acc: 0.1503\n",
      "Epoch 45/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 3.8031 - acc: 0.1497\n",
      "Epoch 46/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 3.7326 - acc: 0.1654\n",
      "Epoch 47/100\n",
      "1723/1723 [==============================] - 84s 49ms/step - loss: 3.7296 - acc: 0.1648\n",
      "Epoch 48/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 4.4298 - acc: 0.1451\n",
      "Epoch 49/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 4.0826 - acc: 0.1422\n",
      "Epoch 50/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 3.8304 - acc: 0.1497\n",
      "Epoch 51/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 3.7491 - acc: 0.1613\n",
      "Epoch 52/100\n",
      "1723/1723 [==============================] - 90s 52ms/step - loss: 3.6602 - acc: 0.1683\n",
      "Epoch 53/100\n",
      "1723/1723 [==============================] - 85s 50ms/step - loss: 3.5946 - acc: 0.1747\n",
      "Epoch 54/100\n",
      "1723/1723 [==============================] - 85s 50ms/step - loss: 3.5355 - acc: 0.1822\n",
      "Epoch 55/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 3.4964 - acc: 0.1869\n",
      "Epoch 56/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 3.4665 - acc: 0.1805\n",
      "Epoch 57/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 3.4428 - acc: 0.1979\n",
      "Epoch 58/100\n",
      "1723/1723 [==============================] - 85s 49ms/step - loss: 3.3747 - acc: 0.1956\n",
      "Epoch 59/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 3.3381 - acc: 0.1991\n",
      "Epoch 60/100\n",
      "1723/1723 [==============================] - 111s 64ms/step - loss: 3.3111 - acc: 0.2055\n",
      "Epoch 61/100\n",
      "1723/1723 [==============================] - 146s 85ms/step - loss: 3.2532 - acc: 0.2159\n",
      "Epoch 62/100\n",
      "1723/1723 [==============================] - 151s 88ms/step - loss: 3.2706 - acc: 0.2049\n",
      "Epoch 63/100\n",
      "1723/1723 [==============================] - 150s 87ms/step - loss: 3.2762 - acc: 0.2043\n",
      "Epoch 64/100\n",
      "1723/1723 [==============================] - 120s 69ms/step - loss: 3.1698 - acc: 0.2200\n",
      "Epoch 65/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 3.1551 - acc: 0.2304\n",
      "Epoch 66/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 3.1230 - acc: 0.2327\n",
      "Epoch 67/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 3.0549 - acc: 0.2327\n",
      "Epoch 68/100\n",
      "1723/1723 [==============================] - 92s 54ms/step - loss: 3.0734 - acc: 0.2322\n",
      "Epoch 69/100\n",
      "1723/1723 [==============================] - 95s 55ms/step - loss: 2.9896 - acc: 0.2420\n",
      "Epoch 70/100\n",
      "1723/1723 [==============================] - 89s 52ms/step - loss: 2.9897 - acc: 0.2501\n",
      "Epoch 71/100\n",
      "1723/1723 [==============================] - 89s 52ms/step - loss: 2.9175 - acc: 0.2577\n",
      "Epoch 72/100\n",
      "1723/1723 [==============================] - 90s 52ms/step - loss: 2.9430 - acc: 0.2577\n",
      "Epoch 73/100\n",
      "1723/1723 [==============================] - 87s 51ms/step - loss: 2.9711 - acc: 0.2472\n",
      "Epoch 74/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 2.8930 - acc: 0.2623\n",
      "Epoch 75/100\n",
      "1723/1723 [==============================] - 89s 51ms/step - loss: 2.8305 - acc: 0.2734\n",
      "Epoch 76/100\n",
      "1723/1723 [==============================] - 89s 52ms/step - loss: 2.8053 - acc: 0.2844\n",
      "Epoch 77/100\n",
      "1723/1723 [==============================] - 89s 51ms/step - loss: 2.8794 - acc: 0.2681\n",
      "Epoch 78/100\n",
      "1723/1723 [==============================] - 89s 52ms/step - loss: 2.8620 - acc: 0.2583\n",
      "Epoch 79/100\n",
      "1723/1723 [==============================] - 91s 53ms/step - loss: 2.8160 - acc: 0.2826\n",
      "Epoch 80/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 2.7497 - acc: 0.2809\n",
      "Epoch 81/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 2.7076 - acc: 0.2786\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1723/1723 [==============================] - 91s 53ms/step - loss: 2.6794 - acc: 0.3012\n",
      "Epoch 83/100\n",
      "1723/1723 [==============================] - 117s 68ms/step - loss: 2.6688 - acc: 0.2995\n",
      "Epoch 84/100\n",
      "1723/1723 [==============================] - 144s 84ms/step - loss: 2.6190 - acc: 0.3134\n",
      "Epoch 85/100\n",
      "1723/1723 [==============================] - 104s 60ms/step - loss: 2.6027 - acc: 0.3076\n",
      "Epoch 86/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 2.6175 - acc: 0.3146\n",
      "Epoch 87/100\n",
      "1723/1723 [==============================] - 89s 52ms/step - loss: 2.5495 - acc: 0.3285\n",
      "Epoch 88/100\n",
      "1723/1723 [==============================] - 89s 51ms/step - loss: 2.5399 - acc: 0.3175\n",
      "Epoch 89/100\n",
      "1723/1723 [==============================] - 126s 73ms/step - loss: 2.4742 - acc: 0.3430\n",
      "Epoch 90/100\n",
      "1723/1723 [==============================] - 143s 83ms/step - loss: 2.4359 - acc: 0.3529\n",
      "Epoch 91/100\n",
      "1723/1723 [==============================] - 151s 87ms/step - loss: 2.4551 - acc: 0.3349\n",
      "Epoch 92/100\n",
      "1723/1723 [==============================] - 672s 390ms/step - loss: 2.4061 - acc: 0.3401\n",
      "Epoch 93/100\n",
      "1723/1723 [==============================] - 3562s 2s/step - loss: 2.3954 - acc: 0.3529\n",
      "Epoch 94/100\n",
      "1723/1723 [==============================] - 786s 456ms/step - loss: 2.4342 - acc: 0.3331\n",
      "Epoch 95/100\n",
      "1723/1723 [==============================] - 1483s 861ms/step - loss: 2.3625 - acc: 0.3685\n",
      "Epoch 96/100\n",
      "1723/1723 [==============================] - 89s 51ms/step - loss: 2.3108 - acc: 0.3749\n",
      "Epoch 97/100\n",
      "1723/1723 [==============================] - 88s 51ms/step - loss: 2.3155 - acc: 0.3772\n",
      "Epoch 98/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 2.3029 - acc: 0.3767\n",
      "Epoch 99/100\n",
      "1723/1723 [==============================] - 86s 50ms/step - loss: 2.2699 - acc: 0.3831\n",
      "Epoch 100/100\n",
      "1723/1723 [==============================] - 87s 50ms/step - loss: 2.2460 - acc: 0.3767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x3aa96fcc0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data[70][0], training_data[70][1], epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"models/model_complete.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(training_data[80][0], training_data[80][1], epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"models/model_complete.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(training_data[90][0], training_data[90][1], epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"models/model_complete.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"models/model_complete.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak friend and enter you not better. ' then with the drift was rock down with left, and then with the first drift was return to rivendell with rivendell at swimming, and seeing the snow drift ' ached. Southwards, far longer, and the birds was sudden then grows noticed on, grows through langstrand and 'things need boromir. Spades was, we came doomed to go boromir. With answered gandalf.\n",
      "\n",
      "Behind with answered gandalf. Until we and our satisfied a deep to dare to admit brief and then with gloom to back until you before the mention gandalf. Behind with a rivendell at aragorn with peregrin! Last now,' and evening, and the whiteness. Then with lead and then grows noticed with seeing the power and snow then grows noticed less, food you was then grows flowed at men at men with veiled to above aragorn with gloom veiled to be while less, the head but we and our satisfied the first drift was little men with rivendell at empty and return to rivendell with rivendell at swimming, and forward. Answered gandalf.\n",
      "\n",
      "Until swimming, and harbourless. Boromir. On, merry. But swift gandalf. Rivendell on, with gandalf.\n",
      "\n",
      "Rivendell with rivendell at swimming, and forward. Southwards, until the first drift was set on, with to rivendell on, with to rivendell southwards, until the snow waited did, and the hobbits up the drift ' again with swimming, and vanished round the rocky turn the ground nigh to return to rivendell with rivendell at aragorn with brightened less, the great snow again!' been cut and sudden gate, off behind us. Maybe he had been moria, but grows ached. Southwards, gandalf. Fast, the air behind with a bridge.\n",
      "\n",
      "Was, we came forced with forward. Southwards, until he came with gloom a road we to should dare to be while less, the head but we and our gate, and night said set but the drift was set with begin grows grass and then grows noticed with forward. Merry and legolas maybe, had been attempt,' said gandalf. There,' grows maybe, had been food you came with forward. Southwards, until the snow was gate, and then grows boromir,' until the invaders was up, last would be moria, but we came with peregrin! Last the hobbits hither.\n",
      "\n",
      "Hither. Followed up, i hope and i cannot felt the little caradhras than aragorn aragorn had and snow drift before knives, rather then he went lands but with gloom a first drift was little men with rivendell at empty and rivendell with rivendell at swimming, and vanished less, light along. For rivendell with rivendell at empty and rivendell with rivendell at swimming, and forward. Answered gandalf. Until swimming, and harbourless.\n",
      "\n",
      "Boromir. On, merry. But swift gandalf. Rivendell southwards, until specks until we have flowed but with swimming, and harbourless. Spades maybe, had been taking journey until we came friendly and then lands southwards, like boromir.\n",
      "\n",
      "Merry. With knives, pointing down sam. With with journey and gate, off be grateful until the hobbits hither. Hither. Followed happily ached.\n",
      "\n",
      "On, at\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Speak friend and enter\"\n",
    "next_words = 500\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            if output_word == 'endofthesentence':\n",
    "                output_word = '.'\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "    \n",
    "seed_text = seed_text.replace('endofthesentence', '.')\n",
    "seed_text = seed_text.replace('pausesentence', ',')\n",
    "seed_text = seed_text.replace('exclamationmark', '!')\n",
    "\n",
    "rtn = re.split('([.!?] *)', seed_text)\n",
    "seed_text = ''.join([each.capitalize() for each in rtn])\n",
    "\n",
    "count_sentences = 0\n",
    "for i in range(len(seed_text)):\n",
    "    if seed_text[i] == '.':\n",
    "        count_sentences += 1\n",
    "        if count_sentences%5 == 0:  \n",
    "            seed_text = seed_text[:i] + '.\\n\\n' + seed_text[i+1:].strip()\n",
    "\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
